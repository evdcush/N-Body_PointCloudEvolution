{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, code, sys, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import cuda\n",
    "from random import randrange\n",
    "from numpy import linalg as LA\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Session, network settings\n",
    "'''\n",
    "params_seed = 98765\n",
    "data_seed   = 12345\n",
    "def seed_rng(s=data_seed):\n",
    "    np.random.seed(s)\n",
    "    tf.set_random_seed(s)\n",
    "    print('seeded by {}'.format(s))\n",
    "\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset parameters\n",
    "'''\n",
    "num_particles = 16 # defaults 16**3\n",
    "zX = 0.6\n",
    "zY = 0.0\n",
    "X_input, X_truth = load_data(num_particles, zX, zY, normalize_data=True)\n",
    "print('Using redshifts z{}, z{}, with {} particles'.format(zX,zY,num_particles**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model parameter initializations\n",
    "'''\n",
    "def init_weight(k_in, k_out):\n",
    "    \"\"\" Initialize weights for fully connected layer\n",
    "    weight drawn from he-normal distribution\n",
    "    Args:\n",
    "        k_in  (int): input channels\n",
    "        k_out (int): output channels\n",
    "    Returns: tf.Variable holding weight of shape (k_in, k_out)\n",
    "    \"\"\"\n",
    "    henorm_std = np.sqrt(2.0 / k_in)\n",
    "    weight = tf.random_normal((k_in, k_out), stddev=henorm_std)\n",
    "    return tf.Variable(weight)\n",
    "\n",
    "def init_graph_weights(k_in, k_out):\n",
    "    \"\"\" initialize weights for graph layer\n",
    "    Two weights:\n",
    "    Wx : weight for external/hidden input\n",
    "    Wg : weight for graph input\n",
    "    \"\"\"\n",
    "    Wx = init_weight(k_in, k_out)\n",
    "    Wg = init_weight(k_in, k_out)\n",
    "    return Wx, Wg\n",
    "\n",
    "def init_bias(k_in, k_out):\n",
    "    \"\"\" initalize bias param\n",
    "    Bias initialized to be near zero\n",
    "    Returns: tf.Variable of shape (k_out,) for bias\n",
    "    \"\"\"\n",
    "    \n",
    "    bias = np.ones(k_out).astype(np.float32) * 1e-6\n",
    "    return tf.Variable(bias)\n",
    "\n",
    "def init_params(channels, graph_weights=True, use_bias=False):\n",
    "    \"\"\" initializes all network hyperparameters\n",
    "    Creates a dict with weights and biases associated with each\n",
    "    hidden layer\n",
    "    Args:\n",
    "        channels (list): list of channel sizes\n",
    "        graph_weights: if true, initializes weights for graph model\n",
    "        use_bias: if true, bias params initialized, else None\n",
    "    Returns: params dict containing weight and biases\n",
    "    \"\"\"\n",
    "    weight_init_fun = init_graph_weights if graph_weights else init_weight\n",
    "    kdims = [(channels[i], channels[i+1]) for i in range(len(channels) - 1)]    \n",
    "    weights = []\n",
    "    biases  = [] if use_bias else None\n",
    "    for ktup in kdims:\n",
    "        weights.append(weight_init_fun(*ktup))     \n",
    "        if use_bias: biases.append(init_bias(*ktup))\n",
    "    params = {'Weights': weights, 'Biases': biases}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeded by 98765\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model\n",
    "'''\n",
    "channels = [6, 8, 16, 32, 16, 8, 3, 8, 16, 32, 16, 8, 3]\n",
    "learning_rate = 0.01\n",
    "batch_size = 8\n",
    "num_iters = 1000\n",
    "seed_rng(params_seed)\n",
    "graph_params = init_params(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Biases': None,\n",
       " 'Weights': [(<tf.Variable 'Variable_72:0' shape=(6, 8) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_73:0' shape=(6, 8) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_74:0' shape=(8, 16) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_75:0' shape=(8, 16) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_76:0' shape=(16, 32) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_77:0' shape=(16, 32) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_78:0' shape=(32, 16) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_79:0' shape=(32, 16) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_80:0' shape=(16, 8) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_81:0' shape=(16, 8) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_82:0' shape=(8, 3) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_83:0' shape=(8, 3) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_84:0' shape=(3, 8) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_85:0' shape=(3, 8) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_86:0' shape=(8, 16) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_87:0' shape=(8, 16) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_88:0' shape=(16, 32) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_89:0' shape=(16, 32) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_90:0' shape=(32, 16) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_91:0' shape=(32, 16) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_92:0' shape=(16, 8) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_93:0' shape=(16, 8) dtype=float32_ref>),\n",
       "  (<tf.Variable 'Variable_94:0' shape=(8, 3) dtype=float32_ref>,\n",
       "   <tf.Variable 'Variable_95:0' shape=(8, 3) dtype=float32_ref>)]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_params\n",
    "'''\n",
    "NOTE:\n",
    "previous tf.Variables instantiaed though init_params are not destroyed\n",
    "upon new calls to graph_params. You can see this by the tf.Variables'\n",
    "default variable names. They just keep getting higher, instead of staying the same.\n",
    "Maybe make a WEIGHT_LABEL and BIAS_LABEL global, init weights with \n",
    "variable name so that there are no unused Variables in graph\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable_30:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_31:0' shape=(32, 16) dtype=float32_ref>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_params['Weights'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-processing: nearest-neighbors and sparse adjacency\n",
    "'''\n",
    "\n",
    "'''\n",
    "SPARSE ADJACENCY MATRIX \n",
    "• scikit learn gives a CRS sparse adjacency for example, sparse TF takes COO. Use this for sparse X dense matmul in TF.\n",
    "• also return adjacency lists and convert alist into index list to be used for generic normalizations (avg, max, etc)\n",
    "\n",
    "tf has a great collection of sparse ops. Has a sparse/dense matmul, which may suit our needs. \n",
    "See which is faster/works:\n",
    "tf.sparse_tensor_dense_matmul\n",
    "tf.sparse_reduce\n",
    "some other combination of csr.indptr and reduceat functions (not sure tf.reduce_mean can take reduction_along indices)\n",
    "'''\n",
    "\n",
    "# returns adjacency lists based on NN in coordinate space\n",
    "def adjacency_list(X_in,k):\n",
    "    shape_in = X_in.shape\n",
    "    X_out = np.zeros([shape_in[0],shape_in[1],k],dtype=np.int32)\n",
    "    for b in range(shape_in[0]):\n",
    "        X_out[b] = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([shape_in[1],k])\n",
    "    return X_out\n",
    "\n",
    "def get_adjacency_list(X_in,k):\n",
    "    \"\"\" search for k nneighbors, and return offsetted indices in adjacency list\n",
    "    \n",
    "    Args:\n",
    "        X_in: input data of shape (mb_size, N, 6)\n",
    "        k: number of nearest neighbors\n",
    "    \"\"\"\n",
    "    mb_size, N, D = X_in.shape\n",
    "    X_out = np.zeros([mb_size, N, k],dtype=np.int32)\n",
    "    for b in range(mb_size):\n",
    "        # this returns indices of the nn\n",
    "        graph_idx = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([N,k]) + (N * b)\n",
    "        X_out[b] = graph_idx\n",
    "    return X_out\n",
    "\n",
    "# adjacency list to proper index list for get_item\n",
    "def alist_to_indexlist(alist):\n",
    "    \"\"\" tiles batch indices to adjacency list for tf.gather\n",
    "    \"\"\"\n",
    "    b, n, k = alist.shape\n",
    "    #b = alist.shape[0] # batch size\n",
    "    #n = alist.shape[1] # set size\n",
    "    #k = alist.shape[2] # number of nn\n",
    "    id1 = np.reshape(np.arange(b),[b,1])\n",
    "    id1 = np.tile(id1,n*k).flatten()\n",
    "    out = np.stack([id1,alist.flatten()],axis=1)\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
