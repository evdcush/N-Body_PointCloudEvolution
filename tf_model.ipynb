{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, code, sys, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import cuda\n",
    "from random import randrange\n",
    "from numpy import linalg as LA\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-47761f70f6d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mxbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (8, n_P, 6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mchx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KNN' is not defined"
     ]
    }
   ],
   "source": [
    "''' \n",
    "See whether indexing ops equivalent\n",
    "chainer.functions.get_item\n",
    "tensorflow.gather\n",
    "'''\n",
    "X = utils.load_datum(32, 0.6, normalize_data=True)\n",
    "\n",
    "xbatch = X[:8] # (8, n_P, 6)\n",
    "\n",
    "knn = KNN(xbatch, 14)\n",
    "\n",
    "chx = chainer.Variable(xbatch)\n",
    "tfx = tf.Variable(xbatch)\n",
    "\n",
    "alist = knn()\n",
    "aflat = alist.flatten()\n",
    "\n",
    "chx_flat = F.reshape(chx, (-1,6))\n",
    "chx_getitem = F.get_item(chx_flat, aflat)\n",
    "chx = F.reshape(chx_getitem, (8, 32768, 14, 6))\n",
    "\n",
    "tfx_flat = tf.reshape(tfx, (-1,6))\n",
    "tfx_gather = tf.gather(tfx_flat, aflat)\n",
    "tfx = tf.reshape(tfx_gather, (8, 32768, 14, 6))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "np.all(tfx.eval() == chx.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 32\n",
    "henorm_std = lambda x: np.sqrt(2.0 / x)\n",
    "weight = tf.random_normal((6,8), stddev=henorm_std(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [6, 8, 16, 32, 16, 8, 3, 8, 16, 32, 16, 8, 3]\n",
    "learning_rate = 0.01\n",
    "batch_size = 8\n",
    "num_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Graph model\n",
    "'''\n",
    "WTAG = 'W{}_{}'\n",
    "BTAG = 'b{}'\n",
    "params = {}\n",
    "\n",
    "channels = [6, 8, 16, 32, 16, 8, 3, 8, 16, 32, 16, 8, 3]\n",
    "num_layers = len(channels) - 1\n",
    "Weights_external = [None] * num_layers\n",
    "Weights_graph    = [None] * num_layers\n",
    "biases = [None] * num_layers\n",
    "\n",
    "henorm_std = lambda x: np.sqrt(2.0 / x)\n",
    "\n",
    "def init_hidden_weight(k_in, k_out):\n",
    "    henorm_std = np.sqrt(2.0 / k_in)\n",
    "    return tf.random_normal((k_in, k_out), stddev=henorm_std)\n",
    "\n",
    "def init_hidden_bias(k_out):\n",
    "    return tf.Variable()\n",
    "\n",
    "\n",
    "def init_params(channels, Wx, Wg, bias=None):\n",
    "    \"\"\" make parameters for each layer\n",
    "    Args:\n",
    "        channels (list): list of layer sizes\n",
    "        Wx       (list): list of weights for external input\n",
    "        Wg       (list): list of weights for graph input\n",
    "        bias     (list): list of biases\n",
    "    \"\"\"\n",
    "    num_layers = len(channels) - 1\n",
    "    for i in range(num_layers):\n",
    "        \n",
    "        \n",
    "\n",
    "def left_mult(T1,T2):\n",
    "    Tout = tf.einsum('ijl,lq->ijq',T1,T2)\n",
    "    return Tout\n",
    "\n",
    "def init\n",
    "\n",
    "def init_params(channels, pdict):\n",
    "    \"\"\" initialize parameters for graph model\n",
    "    Args:\n",
    "        channels (list): layer sizes, 0th is input size, -1th output\n",
    "        pdict (dict): dictionary that holds network parameters\n",
    "    \"\"\"\n",
    "    for i in range(len(channels) - 1):\n",
    "        ch_in, ch_out = channels[i], channels[i+1]\n",
    "        # weight params\n",
    "        w_x = tf.Variable(tf.random_normal([ch_in, ch_out], stddev=std))\n",
    "        w_g = tf.Variable(tf.random_normal([ch_in, ch_out], stddev=std))\n",
    "        # bias\n",
    "        b = tf.Variable((np.ones((ch_out)) * 1e-6).astype(np.float32))\n",
    "        # assign\n",
    "        pdict[WTAG.format('x', i)] = w_x\n",
    "        pdict[WTAG.format('g', i)] = w_g\n",
    "        pdict[BTAG.format(i)] = b\n",
    "    return pdict\n",
    "\n",
    "def set_fwd(h, W):\n",
    "    h_dims = tf.shape(h)\n",
    "    \n",
    "\n",
    "def graph_fwd(h, Wx, Wg, B, adjacency_list):\n",
    "    # note SetLinear is different, mean isnt taken again on graph\n",
    "    \n",
    "    \n",
    "\n",
    "# not sure it matters to make params dynamically because it's tensorflow... everything has to be hardcoded\n",
    "def graph_net(x, adjacency_list):\n",
    "    \"\"\" Graph network\n",
    "    \"\"\"\n",
    "    knn = KNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wg_0': <tf.Variable 'Variable_1:0' shape=(6, 8) dtype=float32_ref>,\n",
       " 'Wg_1': <tf.Variable 'Variable_4:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wg_10': <tf.Variable 'Variable_31:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wg_11': <tf.Variable 'Variable_34:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wg_2': <tf.Variable 'Variable_7:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wg_3': <tf.Variable 'Variable_10:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'Wg_4': <tf.Variable 'Variable_13:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wg_5': <tf.Variable 'Variable_16:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wg_6': <tf.Variable 'Variable_19:0' shape=(3, 8) dtype=float32_ref>,\n",
       " 'Wg_7': <tf.Variable 'Variable_22:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wg_8': <tf.Variable 'Variable_25:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wg_9': <tf.Variable 'Variable_28:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'Wx_0': <tf.Variable 'Variable:0' shape=(6, 8) dtype=float32_ref>,\n",
       " 'Wx_1': <tf.Variable 'Variable_3:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wx_10': <tf.Variable 'Variable_30:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wx_11': <tf.Variable 'Variable_33:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wx_2': <tf.Variable 'Variable_6:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wx_3': <tf.Variable 'Variable_9:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'Wx_4': <tf.Variable 'Variable_12:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wx_5': <tf.Variable 'Variable_15:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wx_6': <tf.Variable 'Variable_18:0' shape=(3, 8) dtype=float32_ref>,\n",
       " 'Wx_7': <tf.Variable 'Variable_21:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wx_8': <tf.Variable 'Variable_24:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wx_9': <tf.Variable 'Variable_27:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'b0': <tf.Variable 'Variable_2:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b1': <tf.Variable 'Variable_5:0' shape=(16,) dtype=float32_ref>,\n",
       " 'b10': <tf.Variable 'Variable_32:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b11': <tf.Variable 'Variable_35:0' shape=(3,) dtype=float32_ref>,\n",
       " 'b2': <tf.Variable 'Variable_8:0' shape=(32,) dtype=float32_ref>,\n",
       " 'b3': <tf.Variable 'Variable_11:0' shape=(16,) dtype=float32_ref>,\n",
       " 'b4': <tf.Variable 'Variable_14:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b5': <tf.Variable 'Variable_17:0' shape=(3,) dtype=float32_ref>,\n",
       " 'b6': <tf.Variable 'Variable_20:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b7': <tf.Variable 'Variable_23:0' shape=(16,) dtype=float32_ref>,\n",
       " 'b8': <tf.Variable 'Variable_26:0' shape=(32,) dtype=float32_ref>,\n",
       " 'b9': <tf.Variable 'Variable_29:0' shape=(16,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rng_seed = 98765 \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Set array backend, seed\n",
    "'''\n",
    "rng_seed = 98765\n",
    "use_gpu = True\n",
    "np.random.seed(rng_seed)\n",
    "print('rng_seed = {} '.format(rng_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using redshifts z0.4, z0.0, with 4096 particles\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dataset parameters\n",
    "'''\n",
    "num_particles = 16 # defaults 16**3\n",
    "zX = 0.4\n",
    "zY = 0.0\n",
    "#zXb = 0.6\n",
    "#zYb = 0.2\n",
    "print('Using redshifts z{}, z{}, with {} particles'.format(zX,zY,num_particles**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1000, 4096, 6)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load training dataset\n",
    "'''\n",
    "X,Y = load_data(zX, zY, num_particles)\n",
    "X = normalize(X)\n",
    "Y = normalize(Y)\n",
    "#Xb, Yb = load_data(zXb, zYb, num_particles)\n",
    "#Xb = normalize(Xb)\n",
    "#Yb = normalize(Yb)\n",
    "print('X.shape: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-processing: nearest-neighbors and sparse adjacency\n",
    "'''\n",
    "\n",
    "'''\n",
    "SPARSE ADJACENCY MATRIX \n",
    "• scikit learn gives a CRS sparse adjacency for example, sparse TF takes COO. Use this for sparse X dense matmul in TF.\n",
    "• also return adjacency lists and convert alist into index list to be used for generic normalizations (avg, max, etc)\n",
    "'''\n",
    "\n",
    "# returns adjacency lists based on NN in coordinate space\n",
    "def adjacency_list(X_in,k):\n",
    "    shape_in = X_in.shape\n",
    "    X_out = np.zeros([shape_in[0],shape_in[1],k],dtype=np.int32)\n",
    "    for b in range(shape_in[0]):\n",
    "        X_out[b] = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([shape_in[1],k])\n",
    "    return X_out\n",
    "\n",
    "def get_adjacency_list(X_in,k):\n",
    "    \"\"\" search for k nneighbors, and return offsetted indices in adjacency list\n",
    "    \n",
    "    Args:\n",
    "        X_in: input data of shape (mb_size, N, 6)\n",
    "        k: number of nearest neighbors\n",
    "    \"\"\"\n",
    "    mb_size, N, D = X_in.shape\n",
    "    X_out = np.zeros([mb_size, N, k],dtype=np.int32)\n",
    "    for b in range(mb_size):\n",
    "        # this returns indices of the nn\n",
    "        graph_idx = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([N,k]) + (N * b)\n",
    "        X_out[b] = graph_idx\n",
    "    return X_out\n",
    "\n",
    "# adjacency list to proper index list for get_item\n",
    "def alist_to_indexlist(alist):\n",
    "    \"\"\" tiles batch indices to adjacency list for tf.gather\n",
    "    \"\"\"\n",
    "    b, n, k = alist.shape\n",
    "    #b = alist.shape[0] # batch size\n",
    "    #n = alist.shape[1] # set size\n",
    "    #k = alist.shape[2] # number of nn\n",
    "    id1 = np.reshape(np.arange(b),[b,1])\n",
    "    id1 = np.tile(id1,n*k).flatten()\n",
    "    out = np.stack([id1,alist.flatten()],axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7f8af2141744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 'bi',lowest loss for graph model with 0.01 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#X_input = tf.placeholder(tf.float32, shape=[None,N_p,k_in], name='X_input')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "channels = [6, 8, 16, 32, 16, 8, 3, 8, 16, 32, 16, 8, 3] # 'bi',lowest loss for graph model with 0.01 8\n",
    "#X_input = tf.placeholder(tf.float32, shape=[None,N_p,k_in], name='X_input')\n",
    "x10 = X[:10]\n",
    "layer1 = tf.layers.Dense(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-db2b520c10dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/P363/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m           \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m           \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/P363/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m           \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m           spec.max_ndim is not None):\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m           raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[1;32m   1032\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
