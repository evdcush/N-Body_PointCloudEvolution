{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, code, sys, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import cuda\n",
    "from random import randrange\n",
    "from numpy import linalg as LA\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # IMPLEMENTATION NOTES\\n - network params: need to make it so param Variables are initialized with a fixed label,\\n   so that only one set of network hyper-params are defined in graph at a time\\n   (so tf.Variable(rand_init_values, name=LABEL.format(i)))\\n - make fwd and network functions\\n - been blackboxing Daniele's periodic boundary code, need to confirm that no extra space or extra loops being used\\n - see how framework-agnostic utils functions are. chainer.cuda.get_array_module should not be a problem if numpy data is sent\\n - compare sparse ops for density graph\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # IMPLEMENTATION NOTES\n",
    " - network params: need to make it so param Variables are initialized with a fixed label,\n",
    "   so that only one set of network hyper-params are defined in graph at a time\n",
    "   (so tf.Variable(rand_init_values, name=LABEL.format(i)))\n",
    " - make fwd and network functions\n",
    " - been blackboxing Daniele's periodic boundary code, need to confirm that no extra space or extra loops being used\n",
    " - see how framework-agnostic utils functions are. chainer.cuda.get_array_module should not be a problem if numpy data is sent\n",
    " - compare sparse ops for density graph\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Session, network settings\n",
    "'''\n",
    "params_seed = 98765\n",
    "data_seed   = 12345\n",
    "def seed_rng(s=data_seed):\n",
    "    np.random.seed(s)\n",
    "    tf.set_random_seed(s)\n",
    "    print('seeded by {}'.format(s))\n",
    "\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeded by 12345\n",
      "Using redshifts z0.6, z0.0, with 4096 particles\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dataset parameters\n",
    "'''\n",
    "num_particles = 16 # defaults 16**3\n",
    "zX = 0.6\n",
    "zY = 0.0\n",
    "#X_input, X_truth = utils.load_data(num_particles, zX, zY, normalize_data=True)\n",
    "rs_start = utils.REDSHIFTS.index(zX)\n",
    "rs_target = utils.REDSHIFTS.index(zY)\n",
    "X = utils.load_npy_data(num_particles) # (11, N, D, 6)\n",
    "X = X[[rs_start, rs_target]] # (2, N, D, 6)\n",
    "X = utils.normalize_fullrs(X)\n",
    "seed_rng()\n",
    "X_train, X_val = utils.multi_split_data_validation(X, num_val_samples=200)\n",
    "X = None # reduce memory overhead\n",
    "#X_input = np.load('X16_06.npy')\n",
    "#X_truth = np.load('X16_00.npy')\n",
    "print('Using redshifts z{}, z{}, with {} particles'.format(zX,zY,num_particles**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_H_LABEL     = 'Wh_{}'\n",
    "WEIGHT_GRAPH_LABEL = 'Wg_{}'\n",
    "BIAS_LABEL   = 'B_{}' # eg 'B_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model parameter initializations\n",
    "'''\n",
    "\n",
    "''' # earlier attempts, without scope, to be deleted\n",
    "def _init_weight(k_in, k_out, var_name):\n",
    "    \"\"\" Initialize weights for fully connected layer\n",
    "    weight drawn from he-normal distribution\n",
    "    Args:\n",
    "        k_in  (int): input channels\n",
    "        k_out (int): output channels\n",
    "    Returns: tf.Variable holding weight of shape (k_in, k_out)\n",
    "    \"\"\"\n",
    "    henorm_std = np.sqrt(2.0 / k_in)\n",
    "    weight = tf.random_normal((k_in, k_out), stddev=henorm_std)\n",
    "    return tf.Variable(weight, name=var_name)\n",
    "\n",
    "def _init_set_weights(k_in, k_out, layer_idx):\n",
    "    \"\"\" initializes weight for fully-connected layer\n",
    "    \"\"\"\n",
    "    Wh = init_weight(k_in, k_out, WEIGHT_H_LABEL.format(layer_idx))\n",
    "    return Wh    \n",
    "\n",
    "def _init_graph_weights(k_in, k_out, layer_idx):\n",
    "    \"\"\" initialize weights for graph layer\n",
    "    Two weights:\n",
    "        Wh : weight for external/hidden input (k_in, k_out)\n",
    "        Wg : weight for graph input (k_in, k_out)\n",
    "    \"\"\"\n",
    "    Wh = init_weight(k_in, k_out, WEIGHT_H_LABEL.format(layer_idx))\n",
    "    Wg = init_weight(k_in, k_out, WEIGHT_GRAPH_LABEL.format(layer_idx))\n",
    "    return Wh, Wg\n",
    "\n",
    "def _init_bias(k_in, k_out, layer_idx):\n",
    "    \"\"\" initalize bias param\n",
    "    Bias initialized to be near zero\n",
    "    Returns: tf.Variable of shape (k_out,) for bias\n",
    "    \"\"\"\n",
    "    bias = np.ones(k_out).astype(np.float32) * 1e-6\n",
    "    return tf.Variable(bias, BIAS_LABEL.format(layer_idx))\n",
    "\n",
    "def _init_params(channels, graph_weights=True, use_bias=False):\n",
    "    \"\"\" initializes all network hyperparameters\n",
    "    Creates a dict with weights and biases associated with each\n",
    "    hidden layer\n",
    "    Args:\n",
    "        channels (list): list of channel sizes\n",
    "        graph_weights: if true, initializes weights for graph model\n",
    "        use_bias: if true, bias params initialized, else None\n",
    "    Returns: params dict containing weight and biases\n",
    "    \"\"\"\n",
    "    weight_init_fun = init_graph_weights if graph_weights else init_set_weights\n",
    "    kdims = [(channels[i], channels[i+1]) for i in range(len(channels) - 1)]    \n",
    "    weights = []\n",
    "    biases  = [] if use_bias else None\n",
    "    for idx, ktup in enumerate(kdims):\n",
    "        weights.append(weight_init_fun(*ktup, idx))     \n",
    "        if use_bias: biases.append(init_bias(*ktup, idx))\n",
    "    params = {'Weights': weights, 'Biases': biases}\n",
    "    return params\n",
    "'''\n",
    "dont_print_cell = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "using tf scope, get\n",
    "PREVIOUS WORK\n",
    "'''\n",
    "def init_weight(k_in, k_out, var_name):\n",
    "    \"\"\" Initialize weights for fully connected layer\n",
    "    weight drawn from glorot normal distribution\n",
    "    Args:\n",
    "        k_in  (int): input channels\n",
    "        k_out (int): output channels\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"Params\", reuse=tf.AUTO_REUSE):\n",
    "        tf.get_variable(var_name, shape=(k_in, k_out), initializer=tf.glorot_normal_initializer())\n",
    "\n",
    "def init_bias(k_in, k_out, layer_idx):\n",
    "    \"\"\" initalize bias param\n",
    "    Bias initialized to be near zero# actually zero for now\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"Params\", reuse=tf.AUTO_REUSE):\n",
    "        # should be init with values near 0\n",
    "        tf.get_variable(var_name, shape=(k_out,), initializer=tf.zeros_initializer())\n",
    "\n",
    "def init_gmodel_params(channels, use_bias=False):\n",
    "    kdims = [(channels[i], channels[i+1]) for i in range(len(channels) - 1)]\n",
    "    for idx, ktup in enumerate(kdims):\n",
    "        # init external/hidden weights\n",
    "        wh_name = WEIGHT_H_LABEL.format(idx)\n",
    "        init_weight(*ktup, wh_name)\n",
    "        # init graph weights\n",
    "        wg_name = WEIGHT_GRAPH_LABEL.format(idx)        \n",
    "        init_weight(*ktup, wg_name)\n",
    "        # bias\n",
    "        if use_bias:\n",
    "            b_name = BIAS_LABEL.format(idx)\n",
    "            init_bias(*ktup, b_name)\n",
    "\n",
    "def init_model_params(channels, use_bias=False):\n",
    "    kdims = [(channels[i], channels[i+1]) for i in range(len(channels) - 1)]\n",
    "    with tf.variable_scope(\"Model\", reuse=tf.AUTO_REUSE):\n",
    "        for idx, ktup in enumerate(kdims):\n",
    "            # init external/hidden weights\n",
    "            wh_name = WEIGHT_H_LABEL.format(idx)\n",
    "            init_weight(*ktup, wh_name)\n",
    "            # bias\n",
    "            if use_bias:\n",
    "                b_name = BIAS_LABEL.format(idx)\n",
    "                init_bias(*ktup, b_name)\n",
    "\n",
    "'''\n",
    "nn ops\n",
    "'''\n",
    "def left_mult(h, w):\n",
    "    return tf.einsum('ijl,lq->ijq', h, w)\n",
    "\n",
    "def linear_fwd(h_in, layer_idx, use_bias):\n",
    "    with tf.variable_scope(\"Params\", reuse=tf.AUTO_REUSE):\n",
    "        weight = tf.get_variable(WEIGHT_H_LABEL.format(layer_idx))\n",
    "        mean   = tf.reduce_mean(h_in, axis=-1, keepdims=True)\n",
    "        h = h_in - mean\n",
    "        h_out = left_mult(h, weight)\n",
    "        if use_bias:\n",
    "            bias = tf.get_variable(BIAS_LABEL.format(layer_idx))\n",
    "            h_out += bias\n",
    "    return h_out\n",
    "\n",
    "def model_fwd(x_in, num_layers, activation=tf.nn.relu, use_bias=False):\n",
    "    with tf.variable_scope(\"Model\", reuse=tf.AUTO_REUSE):\n",
    "        h = x_in\n",
    "        for i in range(num_layers):\n",
    "            #print('model_fwd: {}'.format(i))\n",
    "            h = linear_fwd(h, i, use_bias)\n",
    "            if i != num_layers - 1:\n",
    "                h = activation(h)\n",
    "                print('relu')\n",
    "    return h\n",
    "\n",
    "#train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "def get_readout(h_out):\n",
    "    gt_one  = (tf.sign(h_out - 1) + 1) / 2\n",
    "    ls_zero = -(tf.sign(h_out) - 1) / 2\n",
    "    rest = 1 - gt_one - ls_zero\n",
    "    readout = rest*h_out + gt_one*(h_out - 1) + ls_zero*(1 + h_out)\n",
    "    return readout\n",
    "\n",
    "def periodic_boundary_dist(readout, x_truth):\n",
    "    x_truth_coo = x_truth[...,:3]\n",
    "    dist = tf.minimum(tf.square(readout - x_truth_coo), tf.square(readout - (1 + x_truth_coo)))\n",
    "    dist = tf.minimum(dist, tf.square((1 + readout) - x_truth_coo))\n",
    "    return dist\n",
    "    \n",
    "def pbc_loss(h_out, x_truth):\n",
    "    \"\"\" has been confirmed to be same as chainer implementation\n",
    "    \"\"\"\n",
    "    readout  = get_readout(h_out)\n",
    "    pbc_dist = periodic_boundary_dist(readout, x_truth)\n",
    "    pbc_error = tf.reduce_mean(tf.reduce_sum(pbc_dist, axis=-1))\n",
    "    return pbc_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "USING ESTIMATOR\n",
    "https://www.tensorflow.org/programmers_guide/estimators\n",
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network.py\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeded by 98765\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model\n",
    "'''\n",
    "channels = [6, 8, 16, 32, 16, 8, 3, 8, 16, 32, 16, 8, 3]\n",
    "num_layers = len(channels) - 1\n",
    "learning_rate = 0.01\n",
    "batch_size = 8\n",
    "num_iters = 5000\n",
    "use_bias = False\n",
    "seed_rng(params_seed)\n",
    "#init_graph_params(channels)\n",
    "init_model_params(channels, use_bias=use_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_in   = X_train[0]\n",
    "#X_true = X_train[1]\n",
    "#x_input = tf.constant(X_in[:8])\n",
    "#x_truth = tf.constant(X_true[:8])\n",
    "#x_hat = model_fwd(x_input, num_layers, use_bias=use_bias)\n",
    "#loss = pbc_loss(x_hat, x_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "#sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n",
      "relu\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Optimizer\n",
    "'''\n",
    "X_input = tf.placeholder(tf.float32, shape=[None,num_particles**3, channels[0]], name='X_input')\n",
    "X_truth = tf.placeholder(tf.float32, shape=[None,num_particles**3, channels[0]], name='X_truth')\n",
    "X_hat   = model_fwd(X_input, num_layers, use_bias=use_bias)\n",
    "\n",
    "loss    = pbc_loss(X_hat, X_truth)\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.251520\n",
      "10: 0.240144\n",
      "20: 0.233355\n",
      "30: 0.221081\n",
      "40: 0.210218\n",
      "50: 0.200119\n",
      "60: 0.196554\n",
      "70: 0.195525\n",
      "80: 0.197945\n",
      "90: 0.192908\n",
      "100: 0.193341\n",
      "110: 0.183903\n",
      "120: 0.183942\n",
      "130: 0.178815\n",
      "140: 0.176941\n",
      "150: 0.172329\n",
      "160: 0.169498\n",
      "170: 0.165978\n",
      "180: 0.158941\n",
      "190: 0.155889\n",
      "200: 0.152678\n",
      "210: 0.149722\n",
      "220: 0.148941\n",
      "230: 0.148963\n",
      "240: 0.158321\n",
      "250: 0.148934\n",
      "260: 0.152864\n",
      "270: 0.156077\n",
      "280: 0.142754\n",
      "290: 0.146337\n",
      "300: 0.141850\n",
      "310: 0.144163\n",
      "320: 0.142375\n",
      "330: 0.141666\n",
      "340: 0.137206\n",
      "350: 0.135572\n",
      "360: 0.129909\n",
      "370: 0.134071\n",
      "380: 0.144096\n",
      "390: 0.138124\n",
      "400: 0.140718\n",
      "410: 0.134867\n",
      "420: 0.134956\n",
      "430: 0.132767\n",
      "440: 0.136883\n",
      "450: 0.131865\n",
      "460: 0.138526\n",
      "470: 0.136466\n",
      "480: 0.134323\n",
      "490: 0.143030\n",
      "500: 0.128783\n",
      "510: 0.130846\n",
      "520: 0.137327\n",
      "530: 0.134535\n",
      "540: 0.132111\n",
      "550: 0.137097\n",
      "560: 0.126891\n",
      "570: 0.131311\n",
      "580: 0.129746\n",
      "590: 0.136255\n",
      "600: 0.133243\n",
      "610: 0.130005\n",
      "620: 0.128158\n",
      "630: 0.132696\n",
      "640: 0.135493\n",
      "650: 0.128465\n",
      "660: 0.131367\n",
      "670: 0.127565\n",
      "680: 0.129855\n",
      "690: 0.132196\n",
      "700: 0.133230\n",
      "710: 0.136042\n",
      "720: 0.133982\n",
      "730: 0.132778\n",
      "740: 0.136339\n",
      "750: 0.132681\n",
      "760: 0.133077\n",
      "770: 0.137218\n",
      "780: 0.139166\n",
      "790: 0.126807\n",
      "800: 0.138366\n",
      "810: 0.134029\n",
      "820: 0.134488\n",
      "830: 0.136664\n",
      "840: 0.132262\n",
      "850: 0.132985\n",
      "860: 0.129945\n",
      "870: 0.134437\n",
      "880: 0.129554\n",
      "890: 0.126639\n",
      "900: 0.134603\n",
      "910: 0.136985\n",
      "920: 0.127630\n",
      "930: 0.137325\n",
      "940: 0.134459\n",
      "950: 0.129051\n",
      "960: 0.130484\n",
      "970: 0.130853\n",
      "980: 0.128229\n",
      "990: 0.128613\n",
      "1000: 0.131260\n",
      "1010: 0.134372\n",
      "1020: 0.131411\n",
      "1030: 0.128104\n",
      "1040: 0.134646\n",
      "1050: 0.132093\n",
      "1060: 0.131439\n",
      "1070: 0.133033\n",
      "1080: 0.129650\n",
      "1090: 0.127270\n",
      "1100: 0.129471\n",
      "1110: 0.129360\n",
      "1120: 0.131471\n",
      "1130: 0.137179\n",
      "1140: 0.129853\n",
      "1150: 0.129570\n",
      "1160: 0.135815\n",
      "1170: 0.133054\n",
      "1180: 0.127815\n",
      "1190: 0.135698\n",
      "1200: 0.125798\n",
      "1210: 0.127973\n",
      "1220: 0.137646\n",
      "1230: 0.130519\n",
      "1240: 0.133761\n",
      "1250: 0.135182\n",
      "1260: 0.141026\n",
      "1270: 0.128278\n",
      "1280: 0.127131\n",
      "1290: 0.138582\n",
      "1300: 0.132593\n",
      "1310: 0.126300\n",
      "1320: 0.125549\n",
      "1330: 0.131783\n",
      "1340: 0.129956\n",
      "1350: 0.132796\n",
      "1360: 0.129528\n",
      "1370: 0.130819\n",
      "1380: 0.134970\n",
      "1390: 0.142615\n",
      "1400: 0.126796\n",
      "1410: 0.136646\n",
      "1420: 0.131895\n",
      "1430: 0.132209\n",
      "1440: 0.134137\n",
      "1450: 0.130341\n",
      "1460: 0.126874\n",
      "1470: 0.131088\n",
      "1480: 0.127385\n",
      "1490: 0.129092\n",
      "1500: 0.133232\n",
      "1510: 0.129708\n",
      "1520: 0.127999\n",
      "1530: 0.125544\n",
      "1540: 0.129424\n",
      "1550: 0.127487\n",
      "1560: 0.129796\n",
      "1570: 0.131447\n",
      "1580: 0.129648\n",
      "1590: 0.131800\n",
      "1600: 0.132135\n",
      "1610: 0.137742\n",
      "1620: 0.125388\n",
      "1630: 0.131428\n",
      "1640: 0.132906\n",
      "1650: 0.129519\n",
      "1660: 0.131983\n",
      "1670: 0.139276\n",
      "1680: 0.128926\n",
      "1690: 0.132453\n",
      "1700: 0.131498\n",
      "1710: 0.125904\n",
      "1720: 0.136895\n",
      "1730: 0.137353\n",
      "1740: 0.135747\n",
      "1750: 0.134258\n",
      "1760: 0.130185\n",
      "1770: 0.129988\n",
      "1780: 0.130215\n",
      "1790: 0.124427\n",
      "1800: 0.132872\n",
      "1810: 0.128321\n",
      "1820: 0.132206\n",
      "1830: 0.132007\n",
      "1840: 0.130269\n",
      "1850: 0.138371\n",
      "1860: 0.130222\n",
      "1870: 0.129230\n",
      "1880: 0.129968\n",
      "1890: 0.132845\n",
      "1900: 0.127554\n",
      "1910: 0.131655\n",
      "1920: 0.126878\n",
      "1930: 0.127851\n",
      "1940: 0.131031\n",
      "1950: 0.128456\n",
      "1960: 0.128110\n",
      "1970: 0.132274\n",
      "1980: 0.131903\n",
      "1990: 0.131735\n",
      "2000: 0.128756\n",
      "2010: 0.135867\n",
      "2020: 0.131225\n",
      "2030: 0.133074\n",
      "2040: 0.136700\n",
      "2050: 0.125825\n",
      "2060: 0.127634\n",
      "2070: 0.129113\n",
      "2080: 0.131366\n",
      "2090: 0.128859\n",
      "2100: 0.130595\n",
      "2110: 0.131012\n",
      "2120: 0.133377\n",
      "2130: 0.130707\n",
      "2140: 0.137915\n",
      "2150: 0.133757\n",
      "2160: 0.132562\n",
      "2170: 0.126257\n",
      "2180: 0.129503\n",
      "2190: 0.134494\n",
      "2200: 0.135343\n",
      "2210: 0.127436\n",
      "2220: 0.125775\n",
      "2230: 0.127547\n",
      "2240: 0.127554\n",
      "2250: 0.135852\n",
      "2260: 0.134791\n",
      "2270: 0.130066\n",
      "2280: 0.127924\n",
      "2290: 0.132161\n",
      "2300: 0.124324\n",
      "2310: 0.124146\n",
      "2320: 0.131317\n",
      "2330: 0.131719\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-040fae6c7bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#plt.clf()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0m_x_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mx_in\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0m_x_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_x_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ubc/working/utils.py\u001b[0m in \u001b[0;36mnext_minibatch\u001b[0;34m(X_in, batch_size, data_aug)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_aug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_augmentation_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ubc/working/utils.py\u001b[0m in \u001b[0;36mrandom_augmentation_shift\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0mbatch_coo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mbatch_coo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mgt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_coo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m     \u001b[0mbatch_coo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_coo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_coo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train\n",
    "'''\n",
    "saver = tf.train.Saver()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_history = np.zeros((num_iters))\n",
    "verbose = True\n",
    "#plt.clf()\n",
    "for i in range(num_iters):\n",
    "    _x_batch = utils.next_minibatch(X_train, batch_size, data_aug=True)\n",
    "    x_in   = _x_batch[0]\n",
    "    x_true = _x_batch[1]\n",
    "    \n",
    "    if verbose and i % 10 == 0:\n",
    "        error = sess.run(loss, feed_dict={X_input: x_in, X_truth: x_true})\n",
    "        loss_history[i] = error\n",
    "        print('{}: {:.6f}'.format(i, error))\n",
    "    train.run(feed_dict={X_input: x_in, X_truth: x_true})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "#sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Model/Params/Wh_0:0' shape=(6, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_1:0' shape=(8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_2:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_3:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_4:0' shape=(16, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_5:0' shape=(8, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_6:0' shape=(3, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_7:0' shape=(8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_8:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_9:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_10:0' shape=(16, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_11:0' shape=(8, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_0/Adam:0' shape=(6, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_0/Adam_1:0' shape=(6, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_1/Adam:0' shape=(8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_1/Adam_1:0' shape=(8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_2/Adam:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_2/Adam_1:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_3/Adam:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_3/Adam_1:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_4/Adam:0' shape=(16, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_4/Adam_1:0' shape=(16, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_5/Adam:0' shape=(8, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_5/Adam_1:0' shape=(8, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_6/Adam:0' shape=(3, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_6/Adam_1:0' shape=(3, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_7/Adam:0' shape=(8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_7/Adam_1:0' shape=(8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_8/Adam:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_8/Adam_1:0' shape=(16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_9/Adam:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_9/Adam_1:0' shape=(32, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_10/Adam:0' shape=(16, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_10/Adam_1:0' shape=(16, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_11/Adam:0' shape=(8, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'Model/Params/Wh_11/Adam_1:0' shape=(8, 3) dtype=float32_ref>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-processing: nearest-neighbors and sparse adjacency\n",
    "'''\n",
    "\n",
    "'''\n",
    "SPARSE ADJACENCY MATRIX \n",
    "• scikit learn gives a CRS sparse adjacency for example, sparse TF takes COO. Use this for sparse X dense matmul in TF.\n",
    "• also return adjacency lists and convert alist into index list to be used for generic normalizations (avg, max, etc)\n",
    "\n",
    "tf has a great collection of sparse ops. Has a sparse/dense matmul, which may suit our needs. \n",
    "See which is faster/works:\n",
    "tf.sparse_tensor_dense_matmul\n",
    "tf.sparse_reduce\n",
    "some other combination of csr.indptr and reduceat functions (not sure tf.reduce_mean can take reduction_along indices)\n",
    "'''\n",
    "\n",
    "# returns adjacency lists based on NN in coordinate space\n",
    "def adjacency_list(X_in,k):\n",
    "    shape_in = X_in.shape\n",
    "    X_out = np.zeros([shape_in[0],shape_in[1],k],dtype=np.int32)\n",
    "    for b in range(shape_in[0]):\n",
    "        X_out[b] = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([shape_in[1],k])\n",
    "    return X_out\n",
    "\n",
    "def get_adjacency_list(X_in,k):\n",
    "    \"\"\" search for k nneighbors, and return offsetted indices in adjacency list\n",
    "    \n",
    "    Args:\n",
    "        X_in: input data of shape (mb_size, N, 6)\n",
    "        k: number of nearest neighbors\n",
    "    \"\"\"\n",
    "    mb_size, N, D = X_in.shape\n",
    "    X_out = np.zeros([mb_size, N, k],dtype=np.int32)\n",
    "    for b in range(mb_size):\n",
    "        # this returns indices of the nn\n",
    "        graph_idx = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([N,k]) + (N * b)\n",
    "        X_out[b] = graph_idx\n",
    "    return X_out\n",
    "\n",
    "# adjacency list to proper index list for get_item\n",
    "def alist_to_indexlist(alist):\n",
    "    \"\"\" tiles batch indices to adjacency list for tf.gather\n",
    "    \"\"\"\n",
    "    b, n, k = alist.shape\n",
    "    #b = alist.shape[0] # batch size\n",
    "    #n = alist.shape[1] # set size\n",
    "    #k = alist.shape[2] # number of nn\n",
    "    id1 = np.reshape(np.arange(b),[b,1])\n",
    "    id1 = np.tile(id1,n*k).flatten()\n",
    "    out = np.stack([id1,alist.flatten()],axis=1)\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
