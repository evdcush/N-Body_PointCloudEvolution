{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, code, sys, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import cuda\n",
    "from random import randrange\n",
    "from numpy import linalg as LA\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Graph, neighbors ops\n",
    "'''\n",
    "\n",
    "class KNN():\n",
    "    def __init__(self, X_in, K, shell_fraction=0.1):\n",
    "        self.K = K\n",
    "        self.L_box = 16 if X_in.shape[-2] == 16**3 else 32\n",
    "\n",
    "        # Change shell_fraction for tuning the thickness of the shell to be replicated, must be in range 0-1\n",
    "        # 0: no replication, 1: entire box is replicated to the 26 neighbouring boxes\n",
    "        self.shell_fraction = shell_fraction\n",
    "        self.dL = self.L_box * self.shell_fraction\n",
    "        self.adjacency_list = self.get_adjacency_list_periodic_bc(X_in)\n",
    "\n",
    "    def _get_status(self, coordinate):\n",
    "        \"\"\"\n",
    "        Assign a status to each coordinate (of a particle position inside the box):\n",
    "        1 if 0 < coord < dL, 2 if L- dL < coord < L, 0 otherwise\n",
    "\n",
    "        PARAMS:\n",
    "            coordinate(float)\n",
    "        RETURNS:\n",
    "            status(int). Either 0, 1, or 2\n",
    "        \"\"\"\n",
    "        if coordinate < self.dL:\n",
    "            return 1\n",
    "        elif self.L_box - self.dL < coordinate < self.L_box:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _get_clone(self, particle, k, s):\n",
    "        \"\"\"\n",
    "        Clone a particle otuside of the box.\n",
    "\n",
    "        PARAMS:\n",
    "            particle(np array). 6-dim particle position in phase space\n",
    "            k(int). Index of dimension that needs to be projected outside of the box.\n",
    "            s(int). Status, either 1 or 2. Determines where should be cloned.\n",
    "        RETURNS:\n",
    "            clone(np array). 6-dim cloned particle position in phase space.\n",
    "        \"\"\"\n",
    "        clone = []\n",
    "        for i in range(6):\n",
    "            if i == k:\n",
    "                if s == 1:\n",
    "                    clone.append(particle[i] + self.L_box)\n",
    "                elif s == 2:\n",
    "                    clone.append(particle[i] - self.L_box)\n",
    "            else:\n",
    "                clone.append(particle[i])\n",
    "        return np.array(clone)\n",
    "\n",
    "    def get_adjacency_list_periodic_bc(self, X_in):\n",
    "        \"\"\"\n",
    "        Map inner chunks to outer chunks\n",
    "        \"\"\"\n",
    "        K = self.K\n",
    "        mb_size, N, D = X_in.shape\n",
    "        adj_list = np.zeros([mb_size, N, K], dtype=np.int32)\n",
    "\n",
    "        for i in range(mb_size):\n",
    "            ids_map = {}  # For this batch will map new_id to old_id of cloned particles\n",
    "            new_X = [part for part in X_in[i]]  # Start off with original cube\n",
    "            for j in range(N):\n",
    "                status = [self._get_status(X_in[i, j, k]) for k in range(3)]\n",
    "                if sum(status) == 0:  # Not in the shell --skip\n",
    "                    continue\n",
    "                else:\n",
    "                    for k in range(3):\n",
    "                        if status[k] > 0:\n",
    "                            clone = self._get_clone(particle=X_in[i, j, :], k=k, s=status[k])\n",
    "                            new_X.append(clone)\n",
    "                            ids_map.update({len(new_X) - 1: j})\n",
    "                            for kp in range(k + 1, 3):\n",
    "                                if status[kp] > 0:\n",
    "                                    bi_clone = self._get_clone(particle=clone, k=kp, s=status[kp])\n",
    "                                    new_X.append(bi_clone)\n",
    "                                    ids_map.update({len(new_X) - 1: j})\n",
    "                                    for kpp in range(kp + 1, 3):\n",
    "                                        if status[kpp] > 0:\n",
    "                                            tri_clone = self._get_clone(particle=bi_clone, k=kpp, s=status[kpp])\n",
    "                                            new_X.append(tri_clone)\n",
    "                                            ids_map.update({len(new_X) - 1: j})\n",
    "            new_X = np.array(new_X)\n",
    "            graph_idx = kneighbors_graph(new_X[:, :3], K, include_self=True).indices\n",
    "            graph_idx = graph_idx.reshape([-1, K])[:N, :]  # Only care about original box\n",
    "            # Remap outbox neighbors to original ids\n",
    "            for j in range(N):\n",
    "                for k in range(K):\n",
    "                    if graph_idx[j, k] > N - 1:  # If outside of the box\n",
    "                        graph_idx[j, k] = ids_map.get(graph_idx[j, k])\n",
    "            graph_idx = graph_idx + (N * i)  # offset idx for batches\n",
    "            adj_list[i] = graph_idx\n",
    "        return adj_list\n",
    "    \n",
    "    def __call__(self,):\n",
    "        # just return copy of adjacency list\n",
    "        alist = np.copy(self.adjacency_list)\n",
    "        return alist\n",
    "\n",
    "def graph_convolution(x, knn):\n",
    "    alist = knn().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "See whether indexing ops equivalent\n",
    "chainer.functions.get_item\n",
    "tensorflow.gather\n",
    "'''\n",
    "X = utils.load_datum(32, 0.6, normalize_data=True)\n",
    "\n",
    "xbatch = X[:8] # (8, n_P, 6)\n",
    "\n",
    "knn = KNN(xbatch, 14)\n",
    "\n",
    "chx = chainer.Variable(xbatch)\n",
    "tfx = tf.Variable(xbatch)\n",
    "\n",
    "alist = knn()\n",
    "aflat = alist.flatten()\n",
    "\n",
    "chx_flat = F.reshape(chx, (-1,6))\n",
    "chx_getitem = F.get_item(chx_flat, aflat)\n",
    "chx = F.reshape(chx_getitem, (8, 32768, 14, 6))\n",
    "\n",
    "tfx_flat = tf.reshape(tfx, (-1,6))\n",
    "tfx_gather = tf.gather(tfx_flat, aflat)\n",
    "tfx = tf.reshape(tfx_gather, (8, 32768, 14, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(tfx.eval() == chx.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 32\n",
    "henorm_std = lambda x: np.sqrt(2.0 / x)\n",
    "weight = tf.random_normal((6,8), stddev=henorm_std(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [6, 8, 16, 32, 16, 8, 3, 8, 16, 32, 16, 8, 3]\n",
    "learning_rate = 0.01\n",
    "batch_size = 8\n",
    "num_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Graph model\n",
    "'''\n",
    "WTAG = 'W{}_{}'\n",
    "BTAG = 'b{}'\n",
    "params = {}\n",
    "\n",
    "def left_mult(T1,T2):\n",
    "    Tout = tf.einsum('ijl,lq->ijq',T1,T2)\n",
    "    return Tout\n",
    "\n",
    "def init_params(channels, pdict):\n",
    "    \"\"\" initialize parameters for graph model\n",
    "    Args:\n",
    "        channels (list): layer sizes, 0th is input size, -1th output\n",
    "        pdict (dict): dictionary that holds network parameters\n",
    "    \"\"\"\n",
    "    for i in range(len(channels) - 1):\n",
    "        ch_in, ch_out = channels[i], channels[i+1]\n",
    "        # weight params\n",
    "        w_x = tf.Variable(tf.random_normal([ch_in, ch_out], stddev=std))\n",
    "        w_g = tf.Variable(tf.random_normal([ch_in, ch_out], stddev=std))\n",
    "        # bias\n",
    "        b = tf.Variable((np.ones((ch_out)) * 1e-6).astype(np.float32))\n",
    "        # assign\n",
    "        pdict[WTAG.format('x', i)] = w_x\n",
    "        pdict[WTAG.format('g', i)] = w_g\n",
    "        pdict[BTAG.format(i)] = b\n",
    "    return pdict\n",
    "\n",
    "def set_fwd(h, W):\n",
    "    h_dims = tf.shape(h)\n",
    "    \n",
    "\n",
    "def graph_fwd(h, Wx, Wg, B, adjacency_list):\n",
    "    # note SetLinear is different, mean isnt taken again on graph\n",
    "    \n",
    "    \n",
    "\n",
    "# not sure it matters to make params dynamically because it's tensorflow... everything has to be hardcoded\n",
    "def graph_net(x, adjacency_list):\n",
    "    \"\"\" Graph network\n",
    "    \"\"\"\n",
    "    knn = KNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wg_0': <tf.Variable 'Variable_1:0' shape=(6, 8) dtype=float32_ref>,\n",
       " 'Wg_1': <tf.Variable 'Variable_4:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wg_10': <tf.Variable 'Variable_31:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wg_11': <tf.Variable 'Variable_34:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wg_2': <tf.Variable 'Variable_7:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wg_3': <tf.Variable 'Variable_10:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'Wg_4': <tf.Variable 'Variable_13:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wg_5': <tf.Variable 'Variable_16:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wg_6': <tf.Variable 'Variable_19:0' shape=(3, 8) dtype=float32_ref>,\n",
       " 'Wg_7': <tf.Variable 'Variable_22:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wg_8': <tf.Variable 'Variable_25:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wg_9': <tf.Variable 'Variable_28:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'Wx_0': <tf.Variable 'Variable:0' shape=(6, 8) dtype=float32_ref>,\n",
       " 'Wx_1': <tf.Variable 'Variable_3:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wx_10': <tf.Variable 'Variable_30:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wx_11': <tf.Variable 'Variable_33:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wx_2': <tf.Variable 'Variable_6:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wx_3': <tf.Variable 'Variable_9:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'Wx_4': <tf.Variable 'Variable_12:0' shape=(16, 8) dtype=float32_ref>,\n",
       " 'Wx_5': <tf.Variable 'Variable_15:0' shape=(8, 3) dtype=float32_ref>,\n",
       " 'Wx_6': <tf.Variable 'Variable_18:0' shape=(3, 8) dtype=float32_ref>,\n",
       " 'Wx_7': <tf.Variable 'Variable_21:0' shape=(8, 16) dtype=float32_ref>,\n",
       " 'Wx_8': <tf.Variable 'Variable_24:0' shape=(16, 32) dtype=float32_ref>,\n",
       " 'Wx_9': <tf.Variable 'Variable_27:0' shape=(32, 16) dtype=float32_ref>,\n",
       " 'b0': <tf.Variable 'Variable_2:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b1': <tf.Variable 'Variable_5:0' shape=(16,) dtype=float32_ref>,\n",
       " 'b10': <tf.Variable 'Variable_32:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b11': <tf.Variable 'Variable_35:0' shape=(3,) dtype=float32_ref>,\n",
       " 'b2': <tf.Variable 'Variable_8:0' shape=(32,) dtype=float32_ref>,\n",
       " 'b3': <tf.Variable 'Variable_11:0' shape=(16,) dtype=float32_ref>,\n",
       " 'b4': <tf.Variable 'Variable_14:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b5': <tf.Variable 'Variable_17:0' shape=(3,) dtype=float32_ref>,\n",
       " 'b6': <tf.Variable 'Variable_20:0' shape=(8,) dtype=float32_ref>,\n",
       " 'b7': <tf.Variable 'Variable_23:0' shape=(16,) dtype=float32_ref>,\n",
       " 'b8': <tf.Variable 'Variable_26:0' shape=(32,) dtype=float32_ref>,\n",
       " 'b9': <tf.Variable 'Variable_29:0' shape=(16,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rng_seed = 98765 \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Set array backend, seed\n",
    "'''\n",
    "rng_seed = 98765\n",
    "use_gpu = True\n",
    "np.random.seed(rng_seed)\n",
    "print('rng_seed = {} '.format(rng_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using redshifts z0.4, z0.0, with 4096 particles\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dataset parameters\n",
    "'''\n",
    "num_particles = 16 # defaults 16**3\n",
    "zX = 0.4\n",
    "zY = 0.0\n",
    "#zXb = 0.6\n",
    "#zYb = 0.2\n",
    "print('Using redshifts z{}, z{}, with {} particles'.format(zX,zY,num_particles**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1000, 4096, 6)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load training dataset\n",
    "'''\n",
    "X,Y = load_data(zX, zY, num_particles)\n",
    "X = normalize(X)\n",
    "Y = normalize(Y)\n",
    "#Xb, Yb = load_data(zXb, zYb, num_particles)\n",
    "#Xb = normalize(Xb)\n",
    "#Yb = normalize(Yb)\n",
    "print('X.shape: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-processing: nearest-neighbors and sparse adjacency\n",
    "'''\n",
    "\n",
    "'''\n",
    "SPARSE ADJACENCY MATRIX \n",
    "• scikit learn gives a CRS sparse adjacency for example, sparse TF takes COO. Use this for sparse X dense matmul in TF.\n",
    "• also return adjacency lists and convert alist into index list to be used for generic normalizations (avg, max, etc)\n",
    "'''\n",
    "\n",
    "# returns adjacency lists based on NN in coordinate space\n",
    "def adjacency_list(X_in,k):\n",
    "    shape_in = X_in.shape\n",
    "    X_out = np.zeros([shape_in[0],shape_in[1],k],dtype=np.int32)\n",
    "    for b in range(shape_in[0]):\n",
    "        X_out[b] = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([shape_in[1],k])\n",
    "    return X_out\n",
    "\n",
    "def get_adjacency_list(X_in,k):\n",
    "    \"\"\" search for k nneighbors, and return offsetted indices in adjacency list\n",
    "    \n",
    "    Args:\n",
    "        X_in: input data of shape (mb_size, N, 6)\n",
    "        k: number of nearest neighbors\n",
    "    \"\"\"\n",
    "    mb_size, N, D = X_in.shape\n",
    "    X_out = np.zeros([mb_size, N, k],dtype=np.int32)\n",
    "    for b in range(mb_size):\n",
    "        # this returns indices of the nn\n",
    "        graph_idx = kneighbors_graph(X_in[b,:,:3],k,include_self=True).indices.reshape([N,k]) + (N * b)\n",
    "        X_out[b] = graph_idx\n",
    "    return X_out\n",
    "\n",
    "# adjacency list to proper index list for get_item\n",
    "def alist_to_indexlist(alist):\n",
    "    \"\"\" tiles batch indices to adjacency list for tf.gather\n",
    "    \"\"\"\n",
    "    b, n, k = alist.shape\n",
    "    #b = alist.shape[0] # batch size\n",
    "    #n = alist.shape[1] # set size\n",
    "    #k = alist.shape[2] # number of nn\n",
    "    id1 = np.reshape(np.arange(b),[b,1])\n",
    "    id1 = np.tile(id1,n*k).flatten()\n",
    "    out = np.stack([id1,alist.flatten()],axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7f8af2141744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 'bi',lowest loss for graph model with 0.01 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#X_input = tf.placeholder(tf.float32, shape=[None,N_p,k_in], name='X_input')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "channels = [6, 8, 16, 32, 16, 8, 3, 8, 16, 32, 16, 8, 3] # 'bi',lowest loss for graph model with 0.01 8\n",
    "#X_input = tf.placeholder(tf.float32, shape=[None,N_p,k_in], name='X_input')\n",
    "x10 = X[:10]\n",
    "layer1 = tf.layers.Dense(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-db2b520c10dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/P363/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m           \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m           \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/P363/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m           \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m           spec.max_ndim is not None):\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m           raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[1;32m   1032\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
